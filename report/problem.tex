\CWHeader{Лабораторная работа \textnumero 1 \enquote{Добыча корпуса документов}}

В качестве источников для сбора документации была выбрана биологическая тематика, что обусловлено её актуальностью и возможностью работы с разнообразными текстами. Для этого были использованы два источника данных: Википедия и Большая Российская Энциклопедия (БРЭ).

\item {Википедия} является одним из самых популярных и доступных источников информации. Она охватывает широкий спектр тем, в том числе биологию, и обновляется на регулярной основе, что делает её актуальной. В Википедии статьи подвергаются коллективному редактированию, что повышает вероятность наличия достоверной информации. Одним из преимуществ Википедии является наличие статей на разных языках, что позволяет легко расширять корпус, если в будущем потребуется добавление данных на других языках.

\item {Большая Российская Энциклопедия (БРЭ)} — это авторитетный источник, предоставляющий качественную информацию по широкому спектру научных дисциплин, включая биологию. Использование БРЭ позволяет добавить в корпус более глубинные статьи, доступные только в рамках энциклопедии, а не в открытых источниках.

\subsection{Характеристики корпуса}

После загрузки и очистки данных корпус включает в себя:

\begin{itemize}
    \item {Общее количество документов}: 32 157
    \item {Из Википедии}: 28 434 документа
    \item {Из БРЭ}: 3 723 документа
    \item {Общий размер данных (raw\_html)}: 2.86 ГБ
    \item {Средний размер одного документа}: 89.02 КБ
    \item {Общий размер clean\_text}: 707.8 МБ
    \item {Средний размер clean\_text одного документа}: 22.01 КБ
\end{itemize}

\subsection{Метаинформация и разметка документов}

Каждый документ в корпусе включает в себя важную метаинформацию, такую как:

\begin{itemize}
    \item {URL документа}: Нормализованный URL, который позволяет легко идентифицировать и ссылаться на статьи.
    \item {Текст документа}:
    \begin{itemize}
        \item \texttt{raw\_html} — оригинальный HTML-текст документа.
        \item \texttt{clean\_text} — очищенная версия текста, которая используется для индексации и поиска.
    \end{itemize}
    \item \textbf{Метаданные}:
    \begin{itemize}
        \item \texttt{title} — заголовок статьи.
        \item \texttt{categories} — категории для Википедии.
        \item \texttt{language} — язык документа.
    \end{itemize}
\end{itemize}

Тексты документов были очищены от HTML-тегов и других ненужных элементов, чтобы сохранить только саму информацию.

\subsection{Использование поисковых систем}

Для более глубокого анализа биологической тематики важно уметь задавать более сложные поисковые запросы, чтобы точнее извлекать релевантную информацию.

Примеры запросов:

\begin{itemize}
    \item "Эволюция человека и влияние окружающей среды на адаптацию" — запрос, требующий извлечения информации о взаимодействии эволюции и экологии.
    \item "Клеточные механизмы в биологии старения" — сложный запрос для поиска научных материалов о молекулярных и клеточных аспектах старения.
    \item "Биологическая роль микробиома человека в иммунной системе" — запрос, который требует понимания взаимосвязей между микробиотой и иммунитетом.
\end{itemize}

Каждый из этих запросов требует точности в формулировке, чтобы получить нужную информацию.

Недостатки существующих поисковых систем:

\begin{itemize}
    \item {Встроенный поиск Википедии}:
    \begin{itemize}
        \item Ограниченный синтаксис запросов. Для более сложных запросов, таких как использование нескольких логических операторов и сочетаний категорий, встроенный поиск не всегда даёт точные результаты.
        \item Недостаточная спецификация тем. Например, запрос "микробиома человека" может вернуть страницы о микробах вообще, а не о человеческом микробиоме в частности.
    \end{itemize}
    
    \item {Google Search с ограничением по сайту}:
    \begin{itemize}
        \item Google, хотя и позволяет задать ограничение по сайту, часто включает в результаты материалы, не полностью соответствующие запросу, особенно если запрос сложный и многозначный.
        \item В поисковой выдаче может смешиваться информация из разных областей биологии, например, результаты, связанные с генетикой и молекулярной биологией, могут быть перепутаны, что делает результаты менее релевантными для специфических научных запросов.
    \end{itemize}
\end{itemize}

\setcounter{subsection}{0} 
\pagebreak
\CWHeader{Лабораторная работа \textnumero 2 \enquote{Поисковый робот}}

\subsection{Основные функции робота}

Поисковый робот состоит из нескольких ключевых функций:

\begin{itemize}
    \item \textbf{Инициализация и настройка робота}: На основе конфигурационного файла робот инициализирует необходимые параметры, такие как задержка между запросами, максимальная глубина обхода, минимальное количество слов в статье и другие.
    \item \textbf{Рекурсивный обход}: Робот рекурсивно обходит категории на Википедии или страницы на БРЭ, извлекая URL-адреса страниц для дальнейшей обработки.
    \item \textbf{Загрузка и парсинг страниц}: После извлечения URL роботом загружается HTML-страница и передается в парсер, который очищает страницу от ненужной разметки и извлекает текст.
    \item \textbf{Сохранение данных в MongoDB}: После обработки данных робот сохраняет их в базе данных MongoDB.
    \item \textbf{Обновление данных}: Робот проверяет, нужно ли обновлять уже сохраненные данные, основываясь на времени последнего обновления и изменениях на странице.
    \item \textbf{Поддержка продолжения работы}: Робот сохраняет текущее состояние и может быть остановлен и возобновлен с того места, где был остановлен.
\end{itemize}

\subsection{Реализация поиска по Википедии}

Поиск по Википедии осуществляется с использованием библиотеки \texttt{pywikibot}, которая позволяет программно взаимодействовать с Wikimedia API. Робот начинает с заданной категории и рекурсивно обходит все страницы в категории "Биология" до заданной глубины, извлекая статьи и их метаданные.

\subsection{Реализация поиска по БРЭ}
Для сбора URL статей используется \texttt{sitemap.xml}, который содержит ссылки на статьи. Робот  извлекает все URL статей и передает их в очередь на обработку.

\subsection{Запись данных в базу данных}
Каждый документ содержит следующие поля:

\begin{itemize}
    \item \textbf{url}: Оригинальный URL страницы, с которой был извлечен текст.
    \item \textbf{normalized\_url}: Нормализованный URL, который представляет собой URL без параметров и фрагментов.
    \item \textbf{raw\_html}: Сырой HTML-код страницы, полученный до обработки.
    \item \textbf{clean\_text}: Очищенный текст, извлеченный из HTML-страницы.
    \item \textbf{word\_count}: Количество слов в статье.
    \item \textbf{crawled\_at}: Время обкачки документа в формате Unix timestamp.
    \item \textbf{updated\_at}: Время последнего обновления документа в базе данных.
    \item \textbf{metadata}: Метаинформация о документе, включая заголовок страницы и категории.
\end{itemize}
\pagebreak
\setcounter{subsection}{0} 

\CWHeader{Лабораторная работа \textnumero 3 \enquote{Токенизация}}

Текст разбивается на токены, включая как отдельные слова, так и более сложные элементы, такие как термины с дефисами и числа. Для обработки корпуса, содержащего биологическую тематику, необходимо учитывать специфическую терминологию.

\subsection{Правила токенизации}

Основные правила, используемые для токенизации:

\begin{itemize}
    \item Текст разбивается на токены по пробелам и знакам препинания.
    \item Слова с дефисами сохраняются как единичные токены.
    \item Числа и даты также считаются отдельными токенами.
    \item Апострофы в словах сохраняются в качестве части слова.
    \item Токены приводятся к нижнему регистру.
    \item Специальные символы (например, \&amp;) заменяются на соответствующие символы (\&).
\end{itemize}

\subsection{Пример токенизации}

Пример исходного текста и его токенов:

\begin{quote}
    Исходный текст: "Биология — это наука, изучающая жизнь. Взаимодействие живых существ с окружающей средой изучает биолог."
\end{quote}

После применения процесса токенизации:

\begin{itemize}
    \item "биология"
    \item "это"
    \item "наука"
    \item "изучающая"
    \item "жизнь"
    \item "взаимодействие"
    \item "живых"
    \item "существ"
    \item "с"
    \item "окружающей"
    \item "средой"
    \item "изучает"
    \item "биолог"
\end{itemize}

\subsection{Статистические данные}

\begin{itemize}
    \item \textbf{Общее количество токенов}: 26 863 959 
    \item \textbf{Средняя длина токена}: 7.27 символов
    \item \textbf{Время выполнения токенизации}: 31.73 секунд
    \item \textbf{Скорость токенизации}: 31 551.19 КБ/с
    \item \textbf{Скорость токенов}: 1 992 698 токенов/с
\end{itemize}

\pagebreak
\setcounter{subsection}{0} 

\CWHeader{Лабораторная работа \textnumero 4 \enquote{Стемминг}}

Стемминг — это процесс приведения слов к их корню, который помогает избежать обработки разных словоформ как отдельных слов. В данной задаче был использован алгоритм стемминга на основе алгоритма Портера с модификациями для обработки специфической биологической терминологии, такой как названия видов, латинские термины и научные слова.

\subsection{Правила стемминга}

Для слов, содержащих кириллические буквы, используется алгоритм стемминга, который удаляет общие суффиксы и приводит слово к его основе. Например:
    \begin{itemize}
        \item Суффиксы для глаголов: \texttt{ивши}, \texttt{вшись}, \texttt{ся}, \texttt{сь}.
        \item Суффиксы для прилагательных: \texttt{ее}, \texttt{ые}, \texttt{ого}, \texttt{ими}.
        \item Суффиксы для существительных: \texttt{ов}, \texttt{ев}, \texttt{ий}, \texttt{ям}.
    \end{itemize}
Все буквы \texttt{ё} заменяются на \texttt{е} для уменьшения шума в процессе стемминга.

Числовые токены исключаются из дальнейшего стемминга, так как они не требуют изменения.

В случае латинских и других символов, токены остаются без стемминга.

\end{itemize}

\subsection{Пример стемминга}

Исходные токены и результат их обработки с помощью стемминга представлены в таблице ниже:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Исходный токен} & \textbf{Токен после стемминга} \\
\hline
тюлень & тюлен \\
морское & морск \\
млекопитающее & млекопит \\
семейства & семейст \\
буровато-серая & буровато-сер \\
\hline
\end{tabular}
\caption{Пример стемминга}
\end{table}

\subsection{Статистические данные}

\begin{itemize}
    \item \textbf{Количество токенов до}: 26 863 959
    \item \textbf{Количество токенов после}: 24 527 256
    \item \textbf{Числовые токены}: 2 341 197
    \item \textbf{Измененные токены}: 20 154 263

\end{itemize}


Для оценки качества поиска после внедрения стемминга было проведено несколько тестов. Были сравнины результаты поиска до и после применения стемминга для различных типов запросов.

В результате было замечено, что в некоторых случаях стемминг улучшил результаты поиска, так как теперь все формы слова приводятся к единому корню. Однако, в некоторых случаях, особенно для специфических биологических терминов, стемминг привел к ухудшению точности, так как специфические термины были преобразованы в более общие формы.
\pagebreak
\setcounter{subsection}{0} 
\pagebreak
\CWHeader{Лабораторная работа \textnumero 5 \enquote{Закон Ципфа}}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{zipf.jpg}
\caption{Распределение терминов по частотам и линия Ципфа}
\end{figure}

В процессе выполнения работы был построен график распределения частот терминов по логарифмической шкале. График строится с использованием данных из файла, содержащего частоты терминов, которые были извлечены в процессе токенизации и стемминга. Линия Ципфа накладывается на график для оценки того, насколько хорошо распределение терминов соответствует этому закону.

Из построенного графика видно расхождение с идеальной линией. В корпусе содержится большое количество специализированных терминов, которые используются реже, чем стандартные слова, что вызывает отклонения от теоретического распределения. Стемминг и токенизация могут приводить к удалению редких слов или изменению их формы, что также влияет на частотное распределение.
\pagebreak

\setcounter{subsection}{0} 
\CWHeader{Лабораторная работа \textnumero 6 \enquote{Булев индекс}}

\begin{itemize}
    \item \textbf{Прямой индекс}: Для каждого документа сохраняется его идентификатор (\texttt{doc\_id}, 8 байт), заголовок (\texttt{title}, длина строки + сама строка), и URL (\texttt{url}, длина строки + сама строка).

    Прямой индекс сохраняется в том порядке, в котором документы были обработаны, так как он используется для быстрого доступа к информации о каждом документе.
    
    \item \textbf{Обратный индекс}: Для каждого термина сохраняется его длина (\texttt{term\_size}, 4 байта), сам термин, количество документов, в которых он встречается (\texttt{doc\_count}, 4 байта), и список идентификаторов документов.

    Для обратного индекса использована сортировка терминов в лексикографическом порядке, а затем — по частоте их появления в документах. Это позволяет эффективно искать термины и соответствующие им документы.
    
\end{itemize}

Формат представления данных расширяем, что позволяет в будущем добавить дополнительные поля или оптимизации.

\subsection{Статистические данные}

\begin{itemize}
    \item \textbf{Количество терминов}: 10 543 916
    \item \textbf{Средняя длина терма}: 6.42 символов
    \item \textbf{Средняя длина токена}: 6.58 символов
    \item \textbf{Общее количество токенов}: 24 527 256
    \item \textbf{Время индексации}: 162.89 секунды
    \item \textbf{Скорость индексации}: 150,8 токенов в секунду
    \item \textbf{Скорость индексации на один документ}: 763.3 токенов на документ
    
\end{itemize}
Итоговый индекс занимает 416 МБ

\pagebreak
\setcounter{subsection}{0} 
\CWHeader{Лабораторная работа \textnumero 7 \enquote{Булев поиск}}

Система принимает запросы, состоящие из терминов и логических операторов.
\begin{itemize}
    \item Пробел или два амперсанда $ \texttt{\&\&} $ — логическая операция \texttt{И}.
    \item Две вертикальные палочки \texttt{||} — логическая операция \texttt{ИЛИ}.
    \item Восклицательный знак \texttt{!} — логическая операция \texttt{НЕ}.
    \item Скобки \texttt{()} используются для группировки выражений.
\end{itemize}

\subsection{Алгоритм работы парсера}
Парсер выполняет следующие шаги:
\begin{itemize}
    \item Разделение входного запроса на токены.
    \item Обработка логических операций: \texttt{AND}, \texttt{OR}, \texttt{NOT}.
    \item Применение операций поочередно, начиная с операндов.
    \item Обработка скобок для изменения порядка выполнения операций.
    \item Вывод результата, который содержит список идентификаторов документов, соответствующих запросу.
\end{itemize}

\subsection{Пример запросов}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{result.jpg}
\caption{Результат работы Булева индекса}
\end{figure}

Среднее время выполнения запроса: 5.1 милисекунд

\setcounter{section}{0}

\pagebreak
\setcounter{subsection}{0} 
\CWHeader{Запуск системы поискового робота}

Запуск поискового робота выполняется с помощью команд:

\begin{lstlisting}[language=bash]
docker compose build
docker compose up
\end{lstlisting}
Все логи обхода станиц будут отображатся в консоли

Для того, чтобы запустить "серверы" tokenazer,stemmer,zipf и indexer нужно ввести команду:
\begin{lstlisting}[language=bash]
docker compose --profile name run --rm name
\end{lstlisting}

В консоли отобразятся логи и статистика работы сервисов

Для того, чтобы запустить бинарный поиск (searching) требуется запустить команду:

\begin{lstlisting}[language=bash]
cat test1.txt | docker-compose --profile searching run --rm searching
\end{lstlisting}

\pagebreak